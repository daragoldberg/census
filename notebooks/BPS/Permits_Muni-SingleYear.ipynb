{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull BPS Permit data for NYC Metro municipalities outside of NYC & NYC data from Bytes of the Big Apple - SINGLE YEAR\n",
    "\n",
    "https://www1.nyc.gov/site/planning/data-maps/open-data/dwn-housing-database.page#housingdevelopmentproject\n",
    "\n",
    "For greatest similarity to BPS data, the HousingDB_post2010 (inactives included) file is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo import stco_fips,sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET THESE VARIABLES AND DATA LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_yr = '2010'\n",
    "end_yr = '2020'\n",
    "pull_yr = '2020'\n",
    "\n",
    "#geoxwalk files and data file for NYC\n",
    "geo_subpl = pd.read_csv('../data/geo/subpl10.csv')\n",
    "geo_nyc = pd.read_csv('../data/geo/nyc_subbor_10.csv')\n",
    "\n",
    "nyc_db_datapath = '../data/permits/HousingDB_post2010_inactive_included.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Table for NYC Metro Municipalities (no NYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set link location\n",
    "urls = 'https://www2.census.gov/econ/bps/Place/Northeast%20Region/'\n",
    "resp = requests.get(urls)\n",
    "\n",
    "#pull annual files (\"a\")\n",
    "soup = BeautifulSoup(resp.text,'html.parser')\n",
    "file_links = soup.find_all('a',href = True)\n",
    "file_links = [link.get_text() for link in file_links if 'a.txt' in link.get_text()]\n",
    "#reduce years to what we want vs. all historical files\n",
    "data_yrs = [str(x) for x in range(int(base_yr),int(end_yr)+1)] \n",
    "file_links = [x for x in file_links if x[2:6] in data_yrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = ['36005','36047','36061','36081','36085']\n",
    "\n",
    "# set column names and cleanup data\n",
    "id_fields = ['surveydate','statecode','6-digitid','countycode','fips placecode','fips mcdcode','placename']\n",
    "\n",
    "# each N of units has Buildings, Units, and Valuation columns,\n",
    "val_cols = ['1un_bldg', 'HP1', '1un_val',\n",
    "            '2un_bldg', 'HP2', '2un_val',\n",
    "            '3-4un_bldg', 'HP3-4', '3-4un_val',\n",
    "            '5+un_bldg', 'HP5', '5+un_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build muni table of all data for full Northeast\n",
    "all_data = {year:None for year in file_links}\n",
    "\n",
    "for link in file_links:\n",
    "    rows = requests.get(f'{urls}{link}').text.split('\\n')\n",
    "    row0 = [x.lower() for x in rows[0].split(',')] + ['']\n",
    "    row1 = [x.lower() for x in rows[1].split(',')]\n",
    "    cols = [row0[ind] + col_y for ind, col_y in enumerate(row1)]\n",
    "    \n",
    "    cols_id = [cols.index(x) for x in cols if x in id_fields]\n",
    "    model_colnames = [id_field for id_field in id_fields if id_field in cols] + \\\n",
    "                        val_cols + ['reported_' + colname for colname in val_cols]\n",
    "    \n",
    "    df = pd.read_csv(f'{urls}{link}',header = 1, sep = ',', skipinitialspace=True,\\\n",
    "                     low_memory = False, dtype = str)\n",
    "    \n",
    "    cols_val = cols.index('bldgs')\n",
    "    cols_id += list(range(cols_val,len(df.columns)))\n",
    "    \n",
    "    df = df.iloc[:,cols_id]\n",
    "    df.columns = model_colnames\n",
    "    df['stco'] = df.statecode+df.countycode\n",
    "    df = df[df.stco.isin(stco_fips)].copy()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df['year'] = re.sub('\\D+', '', link)\n",
    "    \n",
    "    all_data[link] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits = pd.concat(all_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce table to rest of metro, cleanup place/cousub codes and adjust Long Island reporting geos\n",
    "permits = permits[~permits['stco'].isin(nyc)].copy()\n",
    "permits['fips_placecode'] = permits.fips_placecode.replace(np.nan,'00000').str.rstrip()\n",
    "permits['id'] = np.where((permits['stco'].isin(['36059','36103']))&(permits['fips_placecode']!='00000'),\\\n",
    "                      (permits.statecode+permits.fips_placecode).str.strip(),(permits.stco+permits.fips_mcdcode).str.strip())\n",
    "permits = permits.dropna(subset=['id'])\n",
    "\n",
    "#join to geo crosswalk data, clean up ids\n",
    "permits.loc[permits['id']=='3607156185',['id']] = '3607147999' #Manually correct Palm Tree NY & Kiryas Joel\n",
    "permits['id'] = permits['id'].astype(int)\n",
    "permits = pd.merge(permits,geo_subpl,on='id',how='left')\n",
    "permits = permits.dropna(subset=['geoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce table to single year\n",
    "permits = permits[permits['year']==pull_yr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced table for final nyc metro munis\n",
    "reg = permits[['geoid','HP1','HP2','HP3-4','HP5']].copy()\n",
    "reg['geoid'] = reg['geoid'].astype(int)\n",
    "for col in reg.columns[1:]:\n",
    "    reg[col]=reg[col].astype(int)\n",
    "reg = reg.rename({'geoid':'id','HP2':'HP24','HP3-4':'HP24'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = reg.groupby(reg.columns,axis=1).sum().groupby(['id']).sum().reset_index()\n",
    "reg['HP']=reg['HP1']+reg['HP24']+reg['HP5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull NYC Housing Database permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data must be downloaded & retrieved from folder in project\n",
    "nyc_db = pd.read_csv(f'{nyc_db_datapath}',low_memory=False)\n",
    "nyc_db.loc[nyc_db.PermitYear==' ','PermitYear'] = np.nan\n",
    "nyc_db['PermitYear'] = pd.to_numeric(nyc_db['PermitYear'])\n",
    "\n",
    "#make tract id, filter for new buildings and pull year\n",
    "nyc_db['ct_id'] = [int(str(block)[:11]) for block in nyc_db.CenBlock10] \n",
    "nyc_db = nyc_db[(nyc_db.Job_Type == 'New Building') & (nyc_db.PermitYear == int(pull_yr))]\n",
    "#separate permits into same categories as BPS data\n",
    "nyc_db['size'] = pd.cut(nyc_db['ClassAProp'],bins=[0.1,1,4,np.inf], include_lowest=False,\n",
    "                                  labels=['HP1','HP24','HP5'])\n",
    "\n",
    "#reduce table and clean up\n",
    "nyc_db = nyc_db[['ct_id','size','ClassAProp']]\n",
    "nyc_db = nyc_db.dropna(subset=['size'])\n",
    "nyc_db['size'] = nyc_db['size'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode to nyc sub borough breakdowns\n",
    "nyc_db = pd.merge(nyc_db,geo_nyc,on='ct_id',how='left')\n",
    "nyc_db = nyc_db.drop(columns=['boro','ct_id','puma','nta_id','nta_nm','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot for decade\n",
    "nyc_db = pd.pivot_table(nyc_db,values='ClassAProp',index=['id'],columns=['size'],\\\n",
    "                        aggfunc=np.sum,fill_value=0,margins=False).reset_index()\n",
    "nyc_db['HP'] = nyc_db['HP1']+nyc_db['HP24']+nyc_db['HP5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine tables into final permits table\n",
    "Calculate subregion, region totals & export to intermediate csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([reg,nyc_db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2020_houperm_m.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>size</th>\n",
       "      <th>id</th>\n",
       "      <th>HP1</th>\n",
       "      <th>HP24</th>\n",
       "      <th>HP5</th>\n",
       "      <th>HP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36005CS</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1979</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36005NE</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>346</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36005W</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3326</td>\n",
       "      <td>3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36047C</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2270</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36047E</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1244</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36047N</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>953</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36047S</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>623</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36047W</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>988</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36061E</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36061L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36061U</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1159</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36061WM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36081NE</td>\n",
       "      <td>17</td>\n",
       "      <td>95</td>\n",
       "      <td>557</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36081NW</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>2809</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36081SE</td>\n",
       "      <td>39</td>\n",
       "      <td>88</td>\n",
       "      <td>1406</td>\n",
       "      <td>1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36081SW</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36085C</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36085N</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>122</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36085S</td>\n",
       "      <td>27</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "size       id  HP1  HP24   HP5    HP\n",
       "0     36005CS    1    40  1979  2020\n",
       "1     36005NE    0    23   346   369\n",
       "2      36005W    4     4  3326  3334\n",
       "3      36047C    2    24  2270  2296\n",
       "4      36047E    0    19  1244  1263\n",
       "5      36047N    1    27   953   981\n",
       "6      36047S   20    45   623   688\n",
       "7      36047W   13    12   988  1013\n",
       "8      36061E    0     0   521   521\n",
       "9      36061L    0     0   349   349\n",
       "10     36061U    0     2  1159  1161\n",
       "11    36061WM    0     0   880   880\n",
       "12    36081NE   17    95   557   669\n",
       "13    36081NW    3    68  2809  2880\n",
       "14    36081SE   39    88  1406  1533\n",
       "15    36081SW    5    32    90   127\n",
       "16     36085C   51    42    16   109\n",
       "17     36085N   40    42   122   204\n",
       "18     36085S   27   166     0   193"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
